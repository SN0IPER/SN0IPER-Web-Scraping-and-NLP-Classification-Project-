{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d5e1af-3656-46cf-b50d-7a92a7980a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3edf9dc0-6d10-4ca3-9f36-35732bf6ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "                    # persal use script\n",
    "                    client_id=\"USk5XOVGH0o4pyKGHk6V_Q\",\n",
    "                    # secret\n",
    "                    client_secret=\"LRJMlKi9Ys3VZIMwWtC93P11WNKbmg\",\n",
    "                    # note\n",
    "                    user_agent=\"MrScraper\",\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0808a3d5-6e91-45a9-9f0c-55f171e1c619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3dec934-ce4b-4fb2-84d0-6d8be2059240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subreddit(display_name='all\\\\hot')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.subreddit('all\\hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "262ab5f7-4855-4f3a-82ca-2180aeca9846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5 newest submissions in r/story\n",
    "# for submission in reddit.subreddit('all').new(limit = 5):\n",
    "#     print(submission.title, submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf9cf0-eb63-49af-a8b0-f77442fd2790",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma = pd.read_csv('project_3_scraped_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1418ec84-72bd-471c-a01e-d414590a2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the the count of number of loops \n",
    "iterations = 1\n",
    "while True:\n",
    "    print('Arise, Sigma!')\n",
    "    print('Initiating Sigma!', iterations)\n",
    "    \n",
    "    # wiping the list to not cause ram to overload and crash\n",
    "    # white bored wiping it clean\n",
    "    ids = []\n",
    "    titles = []\n",
    "    body = []\n",
    "    subreddits = []\n",
    "    num_comments = []\n",
    "    upvotes = []\n",
    "    time_posted = []\n",
    "    time_now = []\n",
    "    time_delta = []\n",
    "    \n",
    "    # Looping through scrapping reddit hot page\n",
    "    print('Sigma! Is downloading rubbish to the mainframe')\n",
    "    for submission in reddit.subreddit('all').hot(limit = None):\n",
    "        \n",
    "\n",
    "    \n",
    "        # update the lists as we go\n",
    "        # id\n",
    "        ids.append(submission.id)\n",
    "    \n",
    "        # title appearing on the front page\n",
    "        titles.append(submission.title)\n",
    "    \n",
    "        # the submissions body - an empty str if a link post\n",
    "        body.append(submission.selftext)\n",
    "    \n",
    "        # number of comoments to the reddit\n",
    "        num_comments.append(submission.num_comments)\n",
    "        \n",
    "        # number of upvotes\n",
    "        upvotes.append(submission.ups)\n",
    "    \n",
    "        # time the reddit was created in linux time\n",
    "        time_posted.append(submission.created_utc)\n",
    "    \n",
    "        # time that reddi was scraped\n",
    "        time_now.append(datetime.datetime.utcnow())\n",
    "    \n",
    "        # time elapsed\n",
    "        time_delta.append(datetime.datetime.utcnow() - \\\n",
    "                          datetime.datetime.utcfromtimestamp(submission.created_utc))\n",
    "                                                         \n",
    "        #subreddit that the reddit was posted in \n",
    "        subreddits.append(submission.subreddit)\n",
    "        \n",
    "    # format as a dataframe\n",
    "    df = pd.DataFrame({'id': ids, 'title': titles, 'text': body, 'num_comments': num_comments, 'upvotes': upvotes, \n",
    "                   'time_posted': time_posted, 'time_now': time_now, 'time_delta': time_delta, 'subreddit': subreddits}) \n",
    "    \n",
    "    # appending scrapes to csv & dropping duplicate posts\n",
    "    print(df.shape) \n",
    "    Sigma = pd.concat([Sigma, df])\n",
    "    print(Sigma.shape)\n",
    "    print('Sigma! Is dropping dupes')\n",
    "    Sigma.drop_duplicates(subset = ['id'],\n",
    "                   inplace = True)\n",
    "    print('Shape w/o duplicates:', Sigma.shape)\n",
    "    Sigma.to_csv('project_3_scraped_dataframe.csv')\n",
    "    iterations += 1\n",
    "    \n",
    "    # the while loop slumbers to scrape new data(every 3hours = 10800 seconds)\n",
    "    print('Slumber Sigma')\n",
    "    time.sleep(10800)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe0b3f-26cc-4025-a2d7-58f1777418b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
